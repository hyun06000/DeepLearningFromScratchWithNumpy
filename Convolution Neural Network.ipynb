{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(x,\n",
    "                ftr,\n",
    "                strd):\n",
    "\n",
    "    '''\n",
    "\n",
    "    ###args\n",
    "\n",
    "    x : input of convolution.\n",
    "            [BATCH, HEIGHT, WIDTH, CHANNEL]\n",
    "    ftr : filter for convolution operation.\n",
    "            [IN CHANNEL, FILTER H, FILTER W, OUT CHANNEL]\n",
    "    strd : filter stride number. \n",
    "            [H STRIDE, W STRIDE]\n",
    "\n",
    "\n",
    "    ###retruns\n",
    "\n",
    "    z : result of convolutional neural network operation. \n",
    "        the input size and the filter size is make new smaple size with stride.\n",
    "        so we call it 'hopes'. then output size is\n",
    "        [BATCH, H HOPES, W HOPES, OUT CHANNEL]\n",
    "    '''\n",
    "\n",
    "    (B,H,W,C) = x.shape\n",
    "    (in_C,f_H,f_W,out_C) = ftr.shape\n",
    "    (strd_H,strd_W) = strd\n",
    "\n",
    "    H_hopes = int((H - f_H)/strd_H + 1)\n",
    "    W_hopes = int((W - f_W)/strd_W + 1)\n",
    "\n",
    "    z = np.zeros((B,H_hopes,W_hopes,out_C))\n",
    "\n",
    "    for b in range(B):#배치에서 한장을 가져옴\n",
    "        for out_ch in range(out_C):\n",
    "            for h in range(H_hopes):#우선 가로로 움직이기 위해 행을 선택해줌\n",
    "                h_start = h*strd_H\n",
    "                for w in range(W_hopes):#이제 선택된 행 안에서 움직임\n",
    "                    w_start = w*strd_W\n",
    "                    f_sum = 0\n",
    "                    for ch in range(C):\n",
    "                        x_ = x[b,\n",
    "                               h_start:h_start+f_H,\n",
    "                               w_start:w_start+f_W,\n",
    "                               ch]\n",
    "                        f_sum += np.sum(x_*ftr[ch,:,:,out_ch])\n",
    "                    z[b,h,w,out_ch]=f_sum\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_transpose(x,\n",
    "                          ftr,\n",
    "                          strd):\n",
    "\n",
    "    '''\n",
    "\n",
    "    ###args\n",
    "\n",
    "    x : input of convolution.\n",
    "            [BATCH, HEIGHT, WIDTH, CHANNEL]\n",
    "    ftr : filter for convolution operation.\n",
    "            [IN CHANNEL, FILTER H, FILTER W, OUT CHANNEL]\n",
    "    strd : filter stride number. \n",
    "            [H STRIDE, W STRIDE]\n",
    "\n",
    "\n",
    "    ###retruns\n",
    "\n",
    "    z : result of convolutional neural network operation. \n",
    "        the input size and the filter size is make new smaple size with stride.\n",
    "        so we call it 'hopes'. then output size is\n",
    "        [BATCH, H HOPES, W HOPES, OUT CHANNEL]\n",
    "    '''\n",
    "\n",
    "    (B,H,W,C) = x.shape\n",
    "    (in_C,f_H,f_W,out_C) = ftr.shape\n",
    "    (strd_H,strd_W) = strd\n",
    "    \n",
    "    H_hopes = (H-1)*strd_H+f_H\n",
    "    W_hopes = (W-1)*strd_W+f_W\n",
    "    \n",
    "    z = np.zeros((B,H_hopes,W_hopes,out_C))\n",
    "    \n",
    "    for b in range(B):#배치에서 한장을 가져옴\n",
    "        for out_ch in range(out_C):\n",
    "            for h in range(H):#우선 가로로 움직이기 위해 행을 선택해줌\n",
    "                for w in range(W):#이제 선택된 행 안에서 움직임\n",
    "                    f_sum = 0\n",
    "                    for ch in range(C):\n",
    "                        x_ = x[b,h,w,ch]\n",
    "                        f_sum += x_*ftr[ch,:,:,out_ch]\n",
    "                    z[b,\n",
    "                      h*strd_H:(h*strd_H)+f_H,\n",
    "                      w*strd_W:(w*strd_W)+f_W,\n",
    "                      out_ch] += f_sum\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_back_prop(fore_delta,\n",
    "                   fore_w,\n",
    "                   fore_strd,\n",
    "                   d_act,\n",
    "                   x,\n",
    "                   fltrs,\n",
    "                   strd):\n",
    "    '''\n",
    "    \n",
    "    !!!warning!!!\n",
    "    you need convolution_transpose function in same class.\n",
    "    \n",
    "    ###args\n",
    "    \n",
    "    fore_delta : a tensor of delta from (l+1)th layer\n",
    "                when your local layer is (l)th layer.\n",
    "                it must be same shape as output.\n",
    "                [BATCH, DELTA_H, DELTA_W, OUT_CANNEL]\n",
    "                \n",
    "    fore_w : a convolution filter from (l+1)th layer.\n",
    "                [IN_CHANNEL, FILTER_H, FILTER_W, OUT_CHANNEL]\n",
    "    \n",
    "    fore_strd : a tuple or list of stride in (l+1)th layer.\n",
    "                [H STRIDE, WSTRIDE]\n",
    "    \n",
    "    d_act : a ndarray which is derivative of activation function \n",
    "    \n",
    "    x : input of local layer\n",
    "        [BATCH, HEIGHT, WIDTH, IN_CHANNEL]\n",
    "        \n",
    "    fltrs : a convolution filter tensor of local layer.\n",
    "                it cna be different shape as fore_w\n",
    "                [IN_CHANNEL, FILTER_H, FILTER_W, OUT_CHANNEL]\n",
    "    \n",
    "    strd : a tuple or list of stride in local layer.\n",
    "                [H STRIDE, WSTRIDE]\n",
    "    \n",
    "    ###returns\n",
    "    \n",
    "    z : a partial drivative of convolution filter.\n",
    "        you need this for update local convolution filter.\n",
    "        so it must be same shape as local convolution filter.\n",
    "        [IN CHANNEL, FILTER_H, FILTER_W, OUT_CHANNEL]\n",
    "    \n",
    "    '''\n",
    "    error =  convolution(fore_delta,fore_w,fore_strd)\n",
    "    delta = error*d_act\n",
    "    \n",
    "    SH,SW = strd[0],strd[1]\n",
    "    (INCH,FH,FW,OUTCH) = filters.shape\n",
    "    (B,DH,DW,OUTCH) = delta.shape\n",
    "    \n",
    "    z = np.zeros_like(fltrs)\n",
    "    for b in range(B):\n",
    "        for h in range(DH):\n",
    "            for w in range(DW):\n",
    "                for outch in range(OUTCH):\n",
    "                    for inch in range(INCH):\n",
    "                        I = inputs[b,\n",
    "                                   h*SH:h*SH+FH,\n",
    "                                   w*SW:w*SW+FW,\n",
    "                                   inch]\n",
    "                        \n",
    "                        D = delta[b,h,w,outch]\n",
    "                        z[inch,:,:,outch] += I*D\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_transpose_back_prop(fore_delta,\n",
    "                             fore_w,\n",
    "                             fore_strd,\n",
    "                             d_act,\n",
    "                             x,\n",
    "                             fltrs,\n",
    "                             strd):\n",
    "    '''\n",
    "    \n",
    "    !!!warning!!!\n",
    "    you need convolution function in same class.\n",
    "    \n",
    "    ###args\n",
    "    \n",
    "    fore_delta : a ndarray of delta from (l+1)th layer\n",
    "                when your local layer is (l)th layer.\n",
    "                it must be same shape as output.\n",
    "                [BATCH, DELTA_H, DELTA_W, OUT_CANNEL]\n",
    "                \n",
    "    fore_w : a ndarray of convolution filter from (l+1)th layer.\n",
    "                [IN_CHANNEL, FILTER_H, FILTER_W, OUT_CHANNEL]\n",
    "    \n",
    "    fore_strd : a tuple or list of stride in (l+1)th layer.\n",
    "                [H STRIDE, W STRIDE]\n",
    "    \n",
    "    d_act : a ndarray which is derivative of activation function \n",
    "    \n",
    "    x : input of local layer\n",
    "        [BATCH, HEIGHT, WIDTH, IN_CHANNEL]\n",
    "        \n",
    "    fltrs : a convolution filter tensor of local layer.\n",
    "                it cna be different shape as fore_w\n",
    "                [IN_CHANNEL, FILTER_H, FILTER_W, OUT_CHANNEL]\n",
    "    \n",
    "    strd : a tuple or list of stride in local layer.\n",
    "                [H STRIDE, WSTRIDE]\n",
    "    \n",
    "    ###returns\n",
    "    \n",
    "    z : a partial drivative of convolution_transpose filter.\n",
    "        you need this for update local convolution_transpose filter.\n",
    "        so it must be same shape as local convolution_transpose filter.\n",
    "        [IN CHANNEL, FILTER_H, FILTER_W, OUT_CHANNEL]\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    error = convolution(fore_delta,fore_w,fore_strd)\n",
    "    delta = error * d_act\n",
    "    \n",
    "    for b in range(B):\n",
    "        for outch in range(outCH):\n",
    "            for inch in range(inCH):\n",
    "                for inh in range(inH):\n",
    "                    for inw in range(inW):\n",
    "\n",
    "                        I = x[b,inh,inw,inch]\n",
    "                        \n",
    "                        D = delta[b,\n",
    "                                 inh*sH : inh*sH+fH,\n",
    "                                 inw*sW : inw*sW+fW,\n",
    "                                 outch]\n",
    "                        z[inch,:,:,outch] += I*D\n",
    "    return z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
